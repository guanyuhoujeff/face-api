{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vd59MkxsdgP0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeffg\\AppData\\Local\\Temp\\ipykernel_21804\\2011928270.py:19: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # device object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded finetune model , output to 8\n"
     ]
    }
   ],
   "source": [
    "now_path = os.getcwd()\n",
    "os.chdir(r\"..\\..\\face-api\\jupyter\")\n",
    "import __init__\n",
    "from faceapi import FaceAPIManager\n",
    "face_api_manager = FaceAPIManager(\n",
    "    detector_model_path=r'C:\\Users\\jeffg\\face-project\\face-api\\model_weights\\face-yolov8-m.pt',\n",
    "    encoder_model_path=r'C:\\Users\\jeffg\\face-project\\face-api\\model_weights\\feifei_face.pt',\n",
    "    emotion_model_path=r\"C:\\Users\\jeffg\\face-project\\face-api\\model_weights\\face-emotion.pth\",\n",
    "    \n",
    "    age_proto_path = r'C:\\Users\\jeffg\\face-project\\face-api\\model_weights\\age_gender_models\\age_detector\\age_deploy.prototxt', \n",
    "    age_model_path = r'C:\\Users\\jeffg\\face-project\\face-api\\model_weights\\age_gender_models\\age_detector\\age_net.caffemodel', \n",
    "    gender_proto_path = r'C:\\Users\\jeffg\\face-project\\face-api\\model_weights\\age_gender_models\\gender_detector\\gender_deploy.prototxt', \n",
    "    gender_model_path = r'C:\\Users\\jeffg\\face-project\\face-api\\model_weights\\age_gender_models\\gender_detector\\gender_net.caffemodel', \n",
    "\n",
    "    device='cuda'\n",
    ")\n",
    "os.chdir(now_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_0_data = pd.read_csv(r\"C:\\Users\\jeffg\\face-project\\dataset\\AdienceGender\\fold_0_data.txt\", delimiter=\"\\t\")\n",
    "fold_1_data = pd.read_csv(r\"C:\\Users\\jeffg\\face-project\\dataset\\AdienceGender\\fold_1_data.txt\", delimiter=\"\\t\")\n",
    "fold_2_data = pd.read_csv(r\"C:\\Users\\jeffg\\face-project\\dataset\\AdienceGender\\fold_2_data.txt\", delimiter=\"\\t\")\n",
    "fold_3_data = pd.read_csv(r\"C:\\Users\\jeffg\\face-project\\dataset\\AdienceGender\\fold_3_data.txt\", delimiter=\"\\t\")\n",
    "fold_4_data = pd.read_csv(r\"C:\\Users\\jeffg\\face-project\\dataset\\AdienceGender\\fold_4_data.txt\", delimiter=\"\\t\")\n",
    "label_data = pd.concat((\n",
    "    fold_0_data, \n",
    "    fold_1_data, \n",
    "    fold_2_data,\n",
    "    fold_3_data,\n",
    "    fold_4_data,\n",
    ")).dropna(subset=['age', \"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_map = {\n",
    "    'f': \"female\",\n",
    "    'm': \"male\",\n",
    "    'u': \"unknow_gender\",\n",
    "}\n",
    "\n",
    "label_data[\"gender\"] = label_data[\"gender\"].apply(lambda x: gender_map[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age category classes, there are 12 age groups\n",
    "ages = [\"(0, 2)\", \"(4, 6)\", \"(8, 12)\", \"(15, 20)\", \"(21, 24)\", \"(25, 32)\",\n",
    "             \"(33, 37)\", \"(38, 43)\", \"(44, 47)\", \"(48, 53)\", \"(54, 59)\", \"(60, 100)\"]\n",
    "\n",
    "\n",
    "\n",
    "# Since there are labels that do not match the classes stated, need to fix them\n",
    "ages_to_fix = {'35': ages[6], '3': ages[0], '55': ages[10], '58': ages[10],\n",
    "                    '22': ages[4], '13': ages[2], '45': ages[8], '36': ages[6],\n",
    "                    '23': ages[4], '57': ages[10], '56': ages[10], '2': ages[0],\n",
    "                    '29': ages[5], '34': ages[6], '42': ages[7], '46': ages[8],\n",
    "                    '32': ages[5], '(38, 48)': ages[7], '(38, 42)': ages[7],\n",
    "                    '(8, 23)': ages[2], '(27, 32)': ages[5]}\n",
    "\n",
    "label_data[\"age_fixed\"] = label_data[\"age\"].apply(lambda x: ages_to_fix[x] if not x in ages else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              female\n",
       "1                male\n",
       "2110    unknow_gender\n",
       "Name: gender, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data[\"gender\"].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': '50458575@N08',\n",
       " 'original_image': '9429464468_1bfc39ecfb_o.jpg',\n",
       " 'face_id': 2281,\n",
       " 'age': '(25, 32)',\n",
       " 'gender': 'female',\n",
       " 'x': 653,\n",
       " 'y': 1023,\n",
       " 'dx': 555,\n",
       " 'dy': 554,\n",
       " 'tilt_ang': 5,\n",
       " 'fiducial_yaw_angle': 30,\n",
       " 'fiducial_score': 70,\n",
       " 'age_fixed': '(25, 32)'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_data.to_dict(\"records\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(face_img_list, face_label_list, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(label_data.to_dict(\"records\"), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12429"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6122"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r\"C:\\Users\\jeffg\\face-project\\dataset\\AdienceGender\\aligned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 12429/12429 [45:13<00:00,  4.58it/s]\n"
     ]
    }
   ],
   "source": [
    "for label_payload in tqdm(train_data):\n",
    "    img = Image.open(os.path.join(data_path, label_payload[\"user_id\"],  \"landmark_aligned_face.%s.%s\"%(label_payload[\"face_id\"], label_payload[\"original_image\"])))\n",
    "    img_array = np.array(img)\n",
    "    faces = face_api_manager.handle(img_array)\n",
    "    if len(faces) > 0:\n",
    "        face = faces[0]\n",
    "        x1,y1,x2,y2  = face.xyxy\n",
    "        face_img = img.crop( face.xyxy)\n",
    "    \n",
    "        ## 年紀\n",
    "        os.makedirs(os.path.join(\"AdienceGender_age\", \"train\" , label_payload[\"age_fixed\"]) , exist_ok=True)\n",
    "        face_img.save(\n",
    "            os.path.join(\n",
    "                \"AdienceGender_age\",\n",
    "                \"train\", \n",
    "                label_payload[\"age_fixed\"], \n",
    "                \"landmark_aligned_face.%s.%s\"%(label_payload[\"face_id\"], label_payload[\"original_image\"])\n",
    "            )\n",
    "        )\n",
    "    \n",
    "        ## Gender\n",
    "        os.makedirs(os.path.join(\"AdienceGender_gender\", \"train\" , label_payload[\"gender\"]) , exist_ok=True)\n",
    "        face_img.save(\n",
    "            os.path.join(\n",
    "                \"AdienceGender_gender\", \n",
    "                \"train\" , \n",
    "                label_payload[\"gender\"], \n",
    "                \"landmark_aligned_face.%s.%s\"%(label_payload[\"face_id\"], label_payload[\"original_image\"])\n",
    "            )\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6122/6122 [20:24<00:00,  5.00it/s]\n"
     ]
    }
   ],
   "source": [
    "for label_payload in tqdm(test_data):\n",
    "    img = Image.open(os.path.join(data_path, label_payload[\"user_id\"],  \"landmark_aligned_face.%s.%s\"%(label_payload[\"face_id\"], label_payload[\"original_image\"])))\n",
    "    img_array = np.array(img)\n",
    "    faces = face_api_manager.handle(img_array)\n",
    "    if len(faces) > 0:\n",
    "        face = faces[0]\n",
    "        x1,y1,x2,y2  = face.xyxy\n",
    "        face_img = img.crop( face.xyxy)\n",
    "    \n",
    "        ## 年紀\n",
    "        os.makedirs(os.path.join(\"AdienceGender_age\", \"test\" , label_payload[\"age_fixed\"]) , exist_ok=True)\n",
    "        face_img.save(\n",
    "            os.path.join(\n",
    "                \"AdienceGender_age\",\n",
    "                \"test\", \n",
    "                label_payload[\"age_fixed\"], \n",
    "                \"landmark_aligned_face.%s.%s\"%(label_payload[\"face_id\"], label_payload[\"original_image\"])\n",
    "            )\n",
    "        )\n",
    "    \n",
    "        ## Gender\n",
    "        os.makedirs(os.path.join(\"AdienceGender_gender\", \"test\" , label_payload[\"gender\"]) , exist_ok=True)\n",
    "        face_img.save(\n",
    "            os.path.join(\n",
    "                \"AdienceGender_gender\", \n",
    "                \"test\" , \n",
    "                label_payload[\"gender\"], \n",
    "                \"landmark_aligned_face.%s.%s\"%(label_payload[\"face_id\"], label_payload[\"original_image\"])\n",
    "            )\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMKG5We5qk8WkqjTIIABfAo",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Face Gender Classification using Transfer Learning with ResNet18 (Acc. 97%)",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "147e673ba1c142e0b5e3a6c1dbd91db8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "392b87160a794522b21421b3b2cf1f13": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3dfe281dea5e44fd915ef88ebf8cf8a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f8eb54035ae4c2bb189089ccf18c4ab",
      "max": 46827520,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e634e445f0c14378b110adfb0475dba7",
      "value": 46827520
     }
    },
    "3f8eb54035ae4c2bb189089ccf18c4ab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "610d3c208aff490c855d1c2a9c833416": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3dfe281dea5e44fd915ef88ebf8cf8a7",
       "IPY_MODEL_95eb44ab771e40dab8eba89a46f13bcb"
      ],
      "layout": "IPY_MODEL_a3d5539afe6a4869a53a1a192753b1e5"
     }
    },
    "95eb44ab771e40dab8eba89a46f13bcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_147e673ba1c142e0b5e3a6c1dbd91db8",
      "placeholder": "​",
      "style": "IPY_MODEL_392b87160a794522b21421b3b2cf1f13",
      "value": " 44.7M/44.7M [09:38&lt;00:00, 81.0kB/s]"
     }
    },
    "a3d5539afe6a4869a53a1a192753b1e5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e634e445f0c14378b110adfb0475dba7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
